import os
import glob
import re
from collections import defaultdict

configfile: "config.yaml"
CLUSTER = json.load(open(config['CLUSTER_JSON']))

# rename variables from config file for clarity downstream
fastq_suffix1 = config["fastq_suffix1"]
fastq_suffix2 = config["fastq_suffix2"]
fastqDir = config["fastqDir"]
bamDir = config["bamDir"]
gvcfDir = config["gvcfDir"]
dbDir = config["dbDir"]
listDir = config["listDir"]
vcfDir = config["vcfDir"]

# grab all samples for R1 to get list of names, no need to look at R2 which should have identical names
SAMPLES = ["ERR1013161"]
"""
SAMPLES = glob.glob(fastqDir + "*" + fastq_suffix1)	
print(SAMPLES)

print("SAMPLES:")
for i in range(len(SAMPLES)):
	SAMPLES[i] = os.path.basename(SAMPLES[i])
	SAMPLES[i] = SAMPLES[i].replace(fastq_suffix1, "")
	print(SAMPLES[i])
"""
LISTS = glob.glob(listDir + "*.list")	
for i in range(len(LISTS)):
	LISTS[i] = os.path.basename(LISTS[i])
	LISTS[i] = re.search('\d+', LISTS[i]).group() # get numerical index of list
	#LISTS[i] = LISTS[i].replace("list", "", 2)
	#LISTS[i] = LISTS[i].replace(".", "")
print(LISTS)

# this directory needs to be made beforehand since it is specified within GATK
os.system("mkdir -p " + dbDir + "tmp")
os.system("mkdir -p " + vcfDir + "tmp")

###
# workflow with rules
###

rule all:
	input:
		#expand(gvcfDir + "{sample}_{list}.raw.g.vcf", sample=SAMPLES, list=LISTS)
		#expand(dbDir + "DB_list{list}", list=LISTS)
		expand(vcfDir + "{list}.vcf", list=LISTS)
	
rule bam2gvcf:
	"""
	This rule scatters analyses over two dimensions: sample name and list file. For each BAM file, one per sample,
	a GVCF is created for all the scaffolds present in a given list file.
	"""
	input:
		ref = config['ref'],
		bam = bamDir + "{sample}_dedupSort.bam",
		l = listDir + "list{list}.list"
	output: 
		gvcf = gvcfDir + "{sample}_{list}.raw.g.vcf",
	resources: 
		cpus = CLUSTER["bam2gvcf"]["n"],
		mem_gb = int(CLUSTER["bam2gvcf"]["mem"]/1000)
	params:
		minPrun = 1,
		minDang = 1
	run:
		command = """module load jdk/1.8.0_45-fasrc01
		/n/home11/bjarnold/gatk-4.1.0.0/gatk HaplotypeCaller \
		--java-options \"-Xmx{resources.mem_gb}g -XX:ParallelGCThreads={resources.cpus}\" \
		-R {input.ref} \
		-I {input.bam} \
		-O {output.gvcf} \
		-L {input.l} \
		--emit-ref-confidence GVCF --min-pruning {params.minPrun} --min-dangling-branch-length {params.minDang}"""

		shell(command)

rule gvcf2DB:
	"""
	This rule gathers results for a given list file name, so the workflow is now scattered in only a single dimension. 
	Here we take many gvcfs for a particular list of scaffolds and combine them into a GenomicsDB.
	Samples are thus gathered by a shared list name, but lists are still scattered.
	"""
	input:
		# NOTE: this waits for all gvcfs to be finished, whereas ou really only need to wait 
		# for all samples from a particular list to be finished
		expand(gvcfDir + "{sample}_{list}.raw.g.vcf", sample=SAMPLES, list=LISTS),
		l = listDir + "list{list}.list"
	output: 
		DBmapfile = dbDir + "DB_mapfile{list}",
		DB = directory(dbDir + "DB_list{list}")
	resources: 
		mem_gb = int(CLUSTER["gvcf2DB"]["mem"]/1000)
	run:
		makeMapFilesForGenomicsDBImport(SAMPLES, LISTS, dbDir, gvcfDir)
		
		command="""module load jdk/1.8.0_45-fasrc01
		/n/home11/bjarnold/gatk-4.1.0.0/gatk GenomicsDBImport \
		--java-options \"-Xmx{resources.mem_gb}g -Xms{resources.mem_gb}g\" \
		--genomicsdb-workspace-path {output.DB} \
		-L {input.l} \
		--tmp-dir={dbDir}tmp \
		--sample-name-map {output.DBmapfile}"""

		shell(command)

rule DB2vcf:
	"""
	This rule uses the genomic databases from the previous step (gvcf2DB) to create VCF files, one per list file. Thus, lists
	are still scattered.
	"""
	input:
		DB = directory(dbDir + "DB_list{list}"),
		ref = config['ref']
	output: 
		vcf = vcfDir + "{list}.vcf"
	resources: 
		mem_gb = int(CLUSTER["DB2vcf"]["mem"]/1000)
	run:
		command="""module load jdk/1.8.0_45-fasrc01
		/n/home11/bjarnold/gatk-4.1.0.0/gatk GenotypeGVCFs \
		--java-options \"-Xmx{resources.mem_gb}g -Xms{resources.mem_gb}g\" \
		-R {input.ref} \
		-V gendb://{input.DB} \
		-O {output.vcf} \
		--tmp-dir={vcfDir}tmp"""

		shell(command)

"""
rule gatherVcfs:
	"""
	This rule gathers all of the VCFs, one per list, into one final VCF
	"""
	input:
		DB = directory(dbDir + "DB_list{list}"),
		ref = config['ref']
	output: 
		vcf = vcfDir + "{list}.vcf"
	resources: 
		mem_gb = int(CLUSTER["DB2vcf"]["mem"]/1000)
	run:
		command="""module load jdk/1.8.0_45-fasrc01
		/n/home11/bjarnold/gatk-4.1.0.0/gatk GenotypeGVCFs \
		--java-options \"-Xmx{resources.mem_gb}g -Xms{resources.mem_gb}g\" \
		-R {input.ref} \
		-V gendb://{input.DB} \
		-O {output.vcf} \
		--tmp-dir={vcfDir}tmp"""

		shell(command)
"""


####
# python helper functions
###

def makeMapFilesForGenomicsDBImport(SAMPLES, LISTS, dbDir, gvcfDir):
	for l in LISTS:
		f=open(dbDir + "DB_mapfile" + l, 'w')
		for s in SAMPLES:
			print(s, gvcfDir + s+"_"+l+".raw.g.vcf", sep="\t", file=f)
		f.close()
